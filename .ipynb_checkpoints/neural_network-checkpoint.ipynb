{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5263817-93ba-4642-871f-37a3a0700e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from preprocessor_class import Preprocessor\n",
    "from functions import f1_metric\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, LeakyReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7eaa265-ec79-4635-935f-d7bd4aee93b2",
   "metadata": {},
   "source": [
    "####  Neural Network\n",
    "\n",
    "This part of the program is largely experimental.  I wanted to test the use of a neural network to see if a simple network would perform well on the data.  Ultimately, a sequential Dense network didn't do better than my other models and adding additional hidden layers, more epochs, and different transformations didn't help much.\n",
    "\n",
    "In the interest of time, I decided it was best to focus on the working models instead of looking to improve the neural network, but I am leaving the notebook for the network here so when I have more time, I can experiment further and see if I can get the network to match or exceed the scores of the boosting, bagging, and ensemble models in my final_models.ipynb notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08592514-7139-4c45-9782-ceb5086015f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sugar_class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Cookie Dough Blizzard Cake, 10 in Cookie Dou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Reeses Peanut Butter Cups Blizzard Cake, 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Chocolate Xtreme Blizzard Cake, 10 in Chocol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Oreo Blizzard Cake, 10 in Oreo Blizzard Cake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>DQ Round Cake, 10 in DQ Round Cake, 10 in DQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52926</th>\n",
       "      <td>1</td>\n",
       "      <td>6 Nuggets 6 Nuggets 6 Nuggets, Tenders Entrees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52927</th>\n",
       "      <td>1</td>\n",
       "      <td>Breast, Bonafide Spicy Chicken Breast, Bonafi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52928</th>\n",
       "      <td>1</td>\n",
       "      <td>Thigh, Bonafide Spicy Chicken Thigh, Bonafide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52929</th>\n",
       "      <td>1</td>\n",
       "      <td>Leg, Bonafide Spicy Chicken Leg, Bonafide Spi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52930</th>\n",
       "      <td>1</td>\n",
       "      <td>Black Pepper, for MTO Shnack Wrapz Black Pepp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52931 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sugar_class                                               text\n",
       "0                5    Cookie Dough Blizzard Cake, 10 in Cookie Dou...\n",
       "1                5    Reeses Peanut Butter Cups Blizzard Cake, 10 ...\n",
       "2                5    Chocolate Xtreme Blizzard Cake, 10 in Chocol...\n",
       "3                5    Oreo Blizzard Cake, 10 in Oreo Blizzard Cake...\n",
       "4                5    DQ Round Cake, 10 in DQ Round Cake, 10 in DQ...\n",
       "...            ...                                                ...\n",
       "52926            1     6 Nuggets 6 Nuggets 6 Nuggets, Tenders Entrees\n",
       "52927            1   Breast, Bonafide Spicy Chicken Breast, Bonafi...\n",
       "52928            1   Thigh, Bonafide Spicy Chicken Thigh, Bonafide...\n",
       "52929            1   Leg, Bonafide Spicy Chicken Leg, Bonafide Spi...\n",
       "52930            1   Black Pepper, for MTO Shnack Wrapz Black Pepp...\n",
       "\n",
       "[52931 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Data/prepared_text_data_sugar.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "549dd94c-3b2f-4cf4-b59d-4dd06090bf95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['sugar_class']\n",
    "\n",
    "#One-Hot_Encoding target variable, train/test split\n",
    "ohe = OneHotEncoder(drop='first', sparse=False)\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X, y, test_size = 0.2, random_state = 200)\n",
    "y_train_raw = y_train_raw.values.reshape(-1, 1)\n",
    "y_test_raw = y_test_raw.values.reshape(-1, 1)\n",
    "y_train = ohe.fit_transform(y_train_raw - 1)\n",
    "y_test = ohe.transform(y_test_raw - 1)\n",
    "\n",
    "#Pre-processing and vectorizing text\n",
    "processor = Preprocessor()\n",
    "X_train_transformed = processor.fit_transform(X_train_raw)\n",
    "X_test_transformed = processor.transform(X_test_raw)\n",
    "vector_pipe = Pipeline([('tfidf', TfidfVectorizer())])\n",
    "X_train_vector = vector_pipe.fit_transform(X_train_transformed)\n",
    "X_test_vector = vector_pipe.transform(X_test_transformed)\n",
    "\n",
    "#Returning independent variables to pd.Dataframe\n",
    "X_train = pd.DataFrame(X_train_vector.toarray(), columns = vector_pipe['tfidf'].get_feature_names())\n",
    "X_test = pd.DataFrame(X_test_vector.toarray(), columns = vector_pipe['tfidf'].get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8de21163-f176-4bfb-8862-38fa59625fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensuring X_train and X_test are proper data types\n",
    "X_train_array = X_train.values if isinstance(X_train, pd.DataFrame) else X_train\n",
    "X_test_array = X_test.values if isinstance(X_test, pd.DataFrame) else X_test\n",
    "\n",
    "y_train_reshaped = np.argmax(y_train, axis = 1)\n",
    "\n",
    "trainCallback = EarlyStopping(monitor='loss', min_delta = 1e-6, patience = 5)\n",
    "\n",
    "reg = l2(0.0001)\n",
    "opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f08a2f39-e4e6-4f17-857d-8fe3f4e16fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "265/265 [==============================] - 27s 100ms/step - loss: 5.7495 - f1_metric: 0.4627 - val_loss: 13.9435 - val_f1_metric: 0.5062\n",
      "Epoch 2/15\n",
      "265/265 [==============================] - 27s 103ms/step - loss: 24.2916 - f1_metric: 0.4824 - val_loss: 34.9437 - val_f1_metric: 0.4615\n",
      "Epoch 3/15\n",
      "265/265 [==============================] - 26s 98ms/step - loss: 46.5264 - f1_metric: 0.4836 - val_loss: 59.1820 - val_f1_metric: 0.3115\n",
      "Epoch 4/15\n",
      "265/265 [==============================] - 26s 99ms/step - loss: 71.7045 - f1_metric: 0.4997 - val_loss: 85.0725 - val_f1_metric: 0.4864\n",
      "Epoch 5/15\n",
      "265/265 [==============================] - 26s 98ms/step - loss: 99.0802 - f1_metric: 0.4704 - val_loss: 113.6235 - val_f1_metric: 0.5096\n",
      "Epoch 6/15\n",
      "265/265 [==============================] - 25s 96ms/step - loss: 128.8708 - f1_metric: 0.4634 - val_loss: 144.1213 - val_f1_metric: 0.4857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x243a71f23d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1800, activation = LeakyReLU(), input_shape = (X_train_array.shape[1],), kernel_regularizer = reg))\n",
    "model.add(Dense(4, activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = f1_metric)\n",
    "model.fit(X_train_array, y_train, epochs = 15, callbacks=[trainCallback], batch_size= 128, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2687310b-84a4-4e91-b7e3-61f2b2fc555e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
