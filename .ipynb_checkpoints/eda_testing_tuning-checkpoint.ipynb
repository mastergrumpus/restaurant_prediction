{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b0d8ad7-80f4-4263-9c5e-3e591871c40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, BaggingClassifier, VotingClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score, log_loss, accuracy_score\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25e87473-7a1e-4300-b48f-cfbc65525488",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('Data/menu_items.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e7e2329-c19f-4b91-9846-d298df9af903",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_columns = ['Restaurant_Item_Name', 'restaurant', 'Item_Name', 'Item_Description', 'Food_Category', 'Sugar']\n",
    "df_relevant = df_raw.loc[:, relevant_columns]\n",
    "df_relevant.dropna(inplace = True)\n",
    "df = df_relevant.sort_values(by = 'Sugar', ascending = False)\n",
    "df = df.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74671707-6363-4ea1-b47f-9f736b73fe23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Restaurant_Item_Name</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>Item_Name</th>\n",
       "      <th>Item_Description</th>\n",
       "      <th>Food_Category</th>\n",
       "      <th>Sugar</th>\n",
       "      <th>sugar_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dairy Queen Cookie Dough Blizzard Cake, 10 in</td>\n",
       "      <td>Dairy Queen</td>\n",
       "      <td>Cookie Dough Blizzard Cake, 10 in</td>\n",
       "      <td>Cookie Dough Blizzard Cake, 10 in w/ Vanilla S...</td>\n",
       "      <td>Desserts</td>\n",
       "      <td>783.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dairy Queen Reeses Peanut Butter Cups Blizzard...</td>\n",
       "      <td>Dairy Queen</td>\n",
       "      <td>Reeses Peanut Butter Cups Blizzard Cake, 10 in</td>\n",
       "      <td>Reeses Peanut Butter Cups Blizzard Cake, 10 in...</td>\n",
       "      <td>Desserts</td>\n",
       "      <td>737.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dairy Queen Chocolate Xtreme Blizzard Cake, 10 in</td>\n",
       "      <td>Dairy Queen</td>\n",
       "      <td>Chocolate Xtreme Blizzard Cake, 10 in</td>\n",
       "      <td>Chocolate Xtreme Blizzard Cake, 10 in w/ Brown...</td>\n",
       "      <td>Desserts</td>\n",
       "      <td>735.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dairy Queen Oreo Blizzard Cake, 10 in</td>\n",
       "      <td>Dairy Queen</td>\n",
       "      <td>Oreo Blizzard Cake, 10 in</td>\n",
       "      <td>Oreo Blizzard Cake, 10 in w/ Oreo Cookie Piece...</td>\n",
       "      <td>Desserts</td>\n",
       "      <td>720.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dairy Queen DQ Round Cake, 10 in</td>\n",
       "      <td>Dairy Queen</td>\n",
       "      <td>DQ Round Cake, 10 in</td>\n",
       "      <td>DQ Round Cake w/ Cake Crunch Filling, Chocolat...</td>\n",
       "      <td>Desserts</td>\n",
       "      <td>569.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52926</th>\n",
       "      <td>Popeyes 6 Nuggets</td>\n",
       "      <td>Popeyes</td>\n",
       "      <td>6 Nuggets</td>\n",
       "      <td>6 Nuggets, Tenders</td>\n",
       "      <td>Entrees</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52927</th>\n",
       "      <td>Popeyes Breast, Bonafide Spicy Chicken</td>\n",
       "      <td>Popeyes</td>\n",
       "      <td>Breast, Bonafide Spicy Chicken</td>\n",
       "      <td>Breast, Bonafide Spicy Chicken</td>\n",
       "      <td>Entrees</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52928</th>\n",
       "      <td>Popeyes Thigh, Bonafide Spicy Chicken</td>\n",
       "      <td>Popeyes</td>\n",
       "      <td>Thigh, Bonafide Spicy Chicken</td>\n",
       "      <td>Thigh, Bonafide Spicy Chicken, 300 Calories or...</td>\n",
       "      <td>Entrees</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52929</th>\n",
       "      <td>Popeyes Leg, Bonafide Spicy Chicken</td>\n",
       "      <td>Popeyes</td>\n",
       "      <td>Leg, Bonafide Spicy Chicken</td>\n",
       "      <td>Leg, Bonafide Spicy Chicken, 200 Calories or U...</td>\n",
       "      <td>Entrees</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52930</th>\n",
       "      <td>Sheetz Black Pepper, for MTO Shnack Wrapz</td>\n",
       "      <td>Sheetz</td>\n",
       "      <td>Black Pepper, for MTO Shnack Wrapz</td>\n",
       "      <td>Black Pepper, for MTO Shnack Wrapz &amp; MTO Slide...</td>\n",
       "      <td>Toppings &amp; Ingredients</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52931 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Restaurant_Item_Name   restaurant  \\\n",
       "0          Dairy Queen Cookie Dough Blizzard Cake, 10 in  Dairy Queen   \n",
       "1      Dairy Queen Reeses Peanut Butter Cups Blizzard...  Dairy Queen   \n",
       "2      Dairy Queen Chocolate Xtreme Blizzard Cake, 10 in  Dairy Queen   \n",
       "3                  Dairy Queen Oreo Blizzard Cake, 10 in  Dairy Queen   \n",
       "4                       Dairy Queen DQ Round Cake, 10 in  Dairy Queen   \n",
       "...                                                  ...          ...   \n",
       "52926                                  Popeyes 6 Nuggets      Popeyes   \n",
       "52927             Popeyes Breast, Bonafide Spicy Chicken      Popeyes   \n",
       "52928              Popeyes Thigh, Bonafide Spicy Chicken      Popeyes   \n",
       "52929                Popeyes Leg, Bonafide Spicy Chicken      Popeyes   \n",
       "52930          Sheetz Black Pepper, for MTO Shnack Wrapz       Sheetz   \n",
       "\n",
       "                                            Item_Name  \\\n",
       "0                   Cookie Dough Blizzard Cake, 10 in   \n",
       "1      Reeses Peanut Butter Cups Blizzard Cake, 10 in   \n",
       "2               Chocolate Xtreme Blizzard Cake, 10 in   \n",
       "3                           Oreo Blizzard Cake, 10 in   \n",
       "4                                DQ Round Cake, 10 in   \n",
       "...                                               ...   \n",
       "52926                                       6 Nuggets   \n",
       "52927                  Breast, Bonafide Spicy Chicken   \n",
       "52928                   Thigh, Bonafide Spicy Chicken   \n",
       "52929                     Leg, Bonafide Spicy Chicken   \n",
       "52930              Black Pepper, for MTO Shnack Wrapz   \n",
       "\n",
       "                                        Item_Description  \\\n",
       "0      Cookie Dough Blizzard Cake, 10 in w/ Vanilla S...   \n",
       "1      Reeses Peanut Butter Cups Blizzard Cake, 10 in...   \n",
       "2      Chocolate Xtreme Blizzard Cake, 10 in w/ Brown...   \n",
       "3      Oreo Blizzard Cake, 10 in w/ Oreo Cookie Piece...   \n",
       "4      DQ Round Cake w/ Cake Crunch Filling, Chocolat...   \n",
       "...                                                  ...   \n",
       "52926                                 6 Nuggets, Tenders   \n",
       "52927                     Breast, Bonafide Spicy Chicken   \n",
       "52928  Thigh, Bonafide Spicy Chicken, 300 Calories or...   \n",
       "52929  Leg, Bonafide Spicy Chicken, 200 Calories or U...   \n",
       "52930  Black Pepper, for MTO Shnack Wrapz & MTO Slide...   \n",
       "\n",
       "                Food_Category  Sugar  sugar_class  \n",
       "0                    Desserts  783.0            5  \n",
       "1                    Desserts  737.0            5  \n",
       "2                    Desserts  735.0            5  \n",
       "3                    Desserts  720.0            5  \n",
       "4                    Desserts  569.0            5  \n",
       "...                       ...    ...          ...  \n",
       "52926                 Entrees    0.0            1  \n",
       "52927                 Entrees    0.0            1  \n",
       "52928                 Entrees    0.0            1  \n",
       "52929                 Entrees    0.0            1  \n",
       "52930  Toppings & Ingredients    0.0            1  \n",
       "\n",
       "[52931 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sugar_classifier(sugar):\n",
    "    if sugar >= 30:\n",
    "        return 5\n",
    "    elif (sugar < 30) & (sugar >= 7):\n",
    "        return 4\n",
    "    elif (sugar < 7) & (sugar > 2):\n",
    "        return 3\n",
    "    elif (sugar <= 2) & (sugar > 0):\n",
    "        return 2\n",
    "    elif sugar == 0:\n",
    "        return 1\n",
    "\n",
    "df['sugar_class'] = df['Sugar'].apply(sugar_classifier)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b34538ee-22e5-4b0a-8688-1b554dfc78f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df_relevant['restaurant'].value_counts()\n",
    "for value, count in value_counts.items():\n",
    "    print(f'{value}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5ed4fee-f205-4125-8fa5-bd4cf7150162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['Restaurant_Item_Name'] + \" \" + df['Item_Name'] + \" \" + df['Item_Description'] + \" \" + df['Food_Category']\n",
    "df.drop(columns = ['Restaurant_Item_Name', 'Item_Name', 'Item_Description', 'Food_Category', 'Sugar'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e7edac3-76cf-4b05-b70e-60466c4100dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['restaurant'] = df['restaurant'].str.split()\n",
    "for index, row in df.iterrows():\n",
    "    for string in row['restaurant']:\n",
    "        df.at[index, 'text'] = df.at[index, 'text'].replace(string, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4b8f289-0f12-4b97-9037-b561f4c98ed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sugar_class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Cookie Dough Blizzard Cake, 10 in Cookie Dou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Reeses Peanut Butter Cups Blizzard Cake, 10 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Chocolate Xtreme Blizzard Cake, 10 in Chocol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Oreo Blizzard Cake, 10 in Oreo Blizzard Cake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>DQ Round Cake, 10 in DQ Round Cake, 10 in DQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52926</th>\n",
       "      <td>1</td>\n",
       "      <td>6 Nuggets 6 Nuggets 6 Nuggets, Tenders Entrees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52927</th>\n",
       "      <td>1</td>\n",
       "      <td>Breast, Bonafide Spicy Chicken Breast, Bonafi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52928</th>\n",
       "      <td>1</td>\n",
       "      <td>Thigh, Bonafide Spicy Chicken Thigh, Bonafide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52929</th>\n",
       "      <td>1</td>\n",
       "      <td>Leg, Bonafide Spicy Chicken Leg, Bonafide Spi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52930</th>\n",
       "      <td>1</td>\n",
       "      <td>Black Pepper, for MTO Shnack Wrapz Black Pepp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52931 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sugar_class                                               text\n",
       "0                5    Cookie Dough Blizzard Cake, 10 in Cookie Dou...\n",
       "1                5    Reeses Peanut Butter Cups Blizzard Cake, 10 ...\n",
       "2                5    Chocolate Xtreme Blizzard Cake, 10 in Chocol...\n",
       "3                5    Oreo Blizzard Cake, 10 in Oreo Blizzard Cake...\n",
       "4                5    DQ Round Cake, 10 in DQ Round Cake, 10 in DQ...\n",
       "...            ...                                                ...\n",
       "52926            1     6 Nuggets 6 Nuggets 6 Nuggets, Tenders Entrees\n",
       "52927            1   Breast, Bonafide Spicy Chicken Breast, Bonafi...\n",
       "52928            1   Thigh, Bonafide Spicy Chicken Thigh, Bonafide...\n",
       "52929            1   Leg, Bonafide Spicy Chicken Leg, Bonafide Spi...\n",
       "52930            1   Black Pepper, for MTO Shnack Wrapz Black Pepp...\n",
       "\n",
       "[52931 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns = 'restaurant', inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77c15ccb-09c9-4720-97e4-631dbfbf8d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('prepared_text_data_sugar.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d132c490-f754-438b-8fbb-b70bff8be60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, data, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data, y=None):\n",
    "        preprocessed_data = [self.stem_doc(doc) for doc in data]\n",
    "        return preprocessed_data\n",
    "\n",
    "    def stem_doc(self, doc):\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        lower_doc = [token.lower() for token in word_tokenize(doc) if token.isalpha()]\n",
    "        filtered_doc = [token for token in lower_doc if token not in stop_words]\n",
    "        stemmed_doc = [stemmer.stem(token) for token in filtered_doc]\n",
    "        return \" \".join(stemmed_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2cb43fb-177c-4b5f-bb72-75475f30f1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score: 0.5982513713262635\n",
      "Log Loss:  0.9766313775364627\n"
     ]
    }
   ],
   "source": [
    "X = df['text']\n",
    "y = df['sugar_class']\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 200)\n",
    "processor = Preprocessor()\n",
    "X_train_transformed = processor.fit_transform(X_train_raw)\n",
    "X_test_transformed = processor.transform(X_test_raw)\n",
    "\n",
    "vector_pipe = Pipeline([('tfidf', TfidfVectorizer())])\n",
    "X_train_vector = vector_pipe.fit_transform(X_train_transformed)\n",
    "X_test_vector = vector_pipe.transform(X_test_transformed)\n",
    "X_train = pd.DataFrame(X_train_vector.toarray(), columns = vector_pipe['tfidf'].get_feature_names())\n",
    "X_test = pd.DataFrame(X_test_vector.toarray(), columns = vector_pipe['tfidf'].get_feature_names())\n",
    "\n",
    "multinb = MultinomialNB()\n",
    "multinb.fit(X_train, y_train)\n",
    "y_pred_baseline = multinb.predict(X_test)\n",
    "y_pred_proba_baseline = multinb.predict_proba(X_test)\n",
    "\n",
    "print(f\"Weighted F1 Score: {f1_score(y_test, y_pred_baseline, average = 'weighted')}\")\n",
    "print(f\"Log Loss:  {log_loss(y_test, y_pred_proba_baseline)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a674d374-88b2-419a-81ed-3723e1670d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score: 0.6021715305623653\n",
      "Log Loss:  1.1526683451434967\n"
     ]
    }
   ],
   "source": [
    "compnb = ComplementNB()\n",
    "compnb.fit(X_train, y_train)\n",
    "y_pred_compnb = compnb.predict(X_test)\n",
    "y_pred_proba_compnb = compnb.predict_proba(X_test)\n",
    "\n",
    "print(f\"Weighted F1 Score: {f1_score(y_test, y_pred_compnb, average = 'weighted')}\")\n",
    "print(f\"Log Loss:  {log_loss(y_test, y_pred_proba_compnb)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2210dfc9-1462-43c7-b266-9ff5e93265d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_to_skip = sorted(random.sample(range(1, 52932), 32931))\n",
    "subset = pd.read_csv('Data/prepared_text_data_sugar.csv', skiprows = lines_to_skip)\n",
    "\n",
    "X_sub = subset['text']\n",
    "y_sub = subset['Sugar_Class']\n",
    "X_train_sub_raw, X_test_sub_raw, y_train_sub, y_test_sub = train_test_split(X_sub, y_sub, test_size = 0.2, random_state = 100)\n",
    "X_train_transformed_sub = processor.fit_transform(X_train_sub_raw)\n",
    "X_test_transformed_sub = processor.transform(X_test_sub_raw)\n",
    "\n",
    "vector_pipe_sub = Pipeline([('tfidf', TfidfVectorizer())])\n",
    "X_train_vector_sub = vector_pipe_sub.fit_transform(X_train_transformed_sub)\n",
    "X_test_vector_sub = vector_pipe_sub.transform(X_test_transformed_sub)\n",
    "X_train_sub = pd.DataFrame(X_train_vector_sub.toarray(), columns = vector_pipe_sub['tfidf'].get_feature_names())\n",
    "X_test_sub = pd.DataFrame(X_test_vector_sub.toarray(), columns = vector_pipe_sub['tfidf'].get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "96e038b0-d8e8-4c42-bb92-029a957c2b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized Search found the following optimal parameters: \n",
      "learning_rate: 0.2977513564547608\n",
      "max_depth: 8\n",
      "min_child_weight: 2\n",
      "\n",
      "Weighted F1 Score (Train): 0.8400278977452622\n",
      "Weighted F1 Score (Test): 0.6952111329477347\n",
      "Log Loss (Train):  0.5694687150081663\n",
      "Log Loss (Test):  0.782527227344457\n",
      "\n",
      "Weighted F1 Score After Hyperparameter Tuning (Train): 0.8729975145964162\n",
      "Weighted F1 Score After Hyperparameter Tuning (Test): 0.7067383656667726\n",
      "Log Loss After Hyperparameter Tuning (Train):  0.49105750232531137\n",
      "Log Loss After Hyperparameter Tuning (Test):  0.7490659579653876\n",
      "Run Time: 6923.436443805695\n"
     ]
    }
   ],
   "source": [
    "start_time_xgb = time.time()\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train_sub, y_train_sub)\n",
    "y_pred_xgb_train = xgb.predict(X_train_sub)\n",
    "y_pred_xgb_test = xgb.predict(X_test_sub)\n",
    "y_proba_xgb_train = xgb.predict_proba(X_train_sub)\n",
    "y_proba_xgb_test = xgb.predict_proba(X_test_sub)\n",
    "\n",
    "xgb_params = {\n",
    "    'learning_rate': uniform(0.1, 0.2),\n",
    "    'max_depth': randint(3, 9),\n",
    "    'min_child_weight': randint(1, 3),\n",
    "}\n",
    "\n",
    "search_xgb = RandomizedSearchCV(xgb, xgb_params, scoring = 'f1_weighted', n_jobs = 1)\n",
    "search_xgb.fit(X_train_sub, y_train_sub)\n",
    "best_parameters = search_xgb.best_params_\n",
    "\n",
    "print('Randomized Search found the following optimal parameters: ')\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print('%s: %r' % (param_name, best_parameters[param_name]))\n",
    "print(\"\")\n",
    "\n",
    "y_pred_xgb_param_train = search_xgb.predict(X_train_sub)\n",
    "y_pred_xgb_param_test = search_xgb.predict(X_test_sub)\n",
    "y_proba_xgb_param_train = search_xgb.predict_proba(X_train_sub)\n",
    "y_proba_xgb_param_test = search_xgb.predict_proba(X_test_sub)\n",
    "\n",
    "end_time_xgb = time.time()\n",
    "\n",
    "print(f\"Weighted F1 Score (Train): {f1_score(y_train_sub, y_pred_xgb_train, average = 'weighted')}\")\n",
    "print(f\"Weighted F1 Score (Test): {f1_score(y_test_sub, y_pred_xgb_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss (Train):  {log_loss(y_train_sub, y_proba_xgb_train)}\")\n",
    "print(f\"Log Loss (Test):  {log_loss(y_test_sub, y_proba_xgb_test)}\")\n",
    "print(\"\")\n",
    "print(f\"Weighted F1 Score After Hyperparameter Tuning (Train): {f1_score(y_train_sub, y_pred_xgb_param_train, average = 'weighted')}\")\n",
    "print(f\"Weighted F1 Score After Hyperparameter Tuning (Test): {f1_score(y_test_sub, y_pred_xgb_param_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss After Hyperparameter Tuning (Train):  {log_loss(y_train_sub, y_proba_xgb_param_train)}\")\n",
    "print(f\"Log Loss After Hyperparameter Tuning (Test):  {log_loss(y_test_sub, y_proba_xgb_param_test)}\")\n",
    "print(f\"Run Time: {end_time_xgb - start_time_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c20fa848-2e4b-4181-8b08-4ddef28afb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score: 0.5283394948236613\n",
      "Log Loss:  1.5541493294978928\n"
     ]
    }
   ],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "ada.fit(X_train, y_train)\n",
    "y_pred_ada = ada.predict(X_test)\n",
    "y_pred_proba_ada = ada.predict_proba(X_test)\n",
    "\n",
    "print(f\"Weighted F1 Score: {f1_score(y_test, y_pred_ada, average = 'weighted')}\")\n",
    "print(f\"Log Loss:  {log_loss(y_test, y_pred_proba_ada)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d1e85149-c8be-4de2-aba3-729a0e06c779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomized Search found the following optimal parameters: \n",
      "max_depth: 8\n",
      "min_samples_leaf: 1\n",
      "min_samples_split: 2\n",
      "n_estimators: 100\n",
      "\n",
      "Weighted F1 Score (Train): 0.9931866485409155\n",
      "Weighted F1 Score (Test): 0.726367897119568\n",
      "Log Loss (Train):  0.18638262212047357\n",
      "Log Loss (Test):  0.7592780225634445\n",
      "\n",
      "Weighted F1 Score After Hyperparameter Tuning (Train): 0.46278718366778837\n",
      "Weighted F1 Score After Hyperparameter Tuning (Test): 0.454376778264133\n",
      "Log Loss After Hyperparameter Tuning (Train):  1.291941409039672\n",
      "Log Loss After Hyperparameter Tuning (Test):  1.3010797081137913\n",
      "Run Time: 237.08182501792908\n"
     ]
    }
   ],
   "source": [
    "start_time_rfc = time.time()\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train_sub, y_train_sub)\n",
    "y_pred_rfc_train = rfc.predict(X_train_sub)\n",
    "y_pred_rfc_test = rfc.predict(X_test_sub)\n",
    "y_proba_rfc_train = rfc.predict_proba(X_train_sub)\n",
    "y_proba_rfc_test = rfc.predict_proba(X_test_sub)\n",
    "\n",
    "rfc_params = {\n",
    "    'n_estimators':  [10, 50, 100],\n",
    "    'max_depth':  randint(3, 9),\n",
    "    'min_samples_split':  randint(2, 4),\n",
    "    'min_samples_leaf':  randint(1, 3),\n",
    "}\n",
    "\n",
    "search_rfc = RandomizedSearchCV(rfc, rfc_params, scoring = 'f1_weighted', n_jobs = 1)\n",
    "search_rfc.fit(X_train_sub, y_train_sub)\n",
    "best_parameters = search_rfc.best_params_\n",
    "\n",
    "print('Randomized Search found the following optimal parameters: ')\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print('%s: %r' % (param_name, best_parameters[param_name]))\n",
    "print(\"\")\n",
    "\n",
    "y_pred_rfc_param_train = search_rfc.predict(X_train_sub)\n",
    "y_pred_rfc_param_test = search_rfc.predict(X_test_sub)\n",
    "y_proba_rfc_param_train = search_rfc.predict_proba(X_train_sub)\n",
    "y_proba_rfc_param_test = search_rfc.predict_proba(X_test_sub)\n",
    "\n",
    "end_time_rfc = time.time()\n",
    "\n",
    "print(f\"Weighted F1 Score (Train): {f1_score(y_train_sub, y_pred_rfc_train, average = 'weighted')}\")\n",
    "print(f\"Weighted F1 Score (Test): {f1_score(y_test_sub, y_pred_rfc_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss (Train):  {log_loss(y_train_sub, y_proba_rfc_train)}\")\n",
    "print(f\"Log Loss (Test):  {log_loss(y_test_sub, y_proba_rfc_test)}\")\n",
    "print(\"\")\n",
    "print(f\"Weighted F1 Score After Hyperparameter Tuning (Train): {f1_score(y_train_sub, y_pred_rfc_param_train, average = 'weighted')}\")\n",
    "print(f\"Weighted F1 Score After Hyperparameter Tuning (Test): {f1_score(y_test_sub, y_pred_rfc_param_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss After Hyperparameter Tuning (Train):  {log_loss(y_train_sub, y_proba_rfc_param_train)}\")\n",
    "print(f\"Log Loss After Hyperparameter Tuning (Test):  {log_loss(y_test_sub, y_proba_rfc_param_test)}\")\n",
    "print(f\"Run Time: {end_time_rfc - start_time_rfc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f012d084-0c22-4738-9529-3c70af56d723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Time: 205.5940968990326\n",
      "Weighted F1 Score (Train): 0.9459045001884633\n",
      "Weighted F1 Score (Test): 0.7475568522988201\n",
      "Log Loss (Train):  0.414485587412872\n",
      "Log Loss (Test):  0.6888136677530962\n"
     ]
    }
   ],
   "source": [
    "start_time_rfc1 = time.time()\n",
    "\n",
    "rfc1 = RandomForestClassifier(n_estimators = 200,\n",
    "                              criterion = 'gini',\n",
    "                              max_depth = None,\n",
    "                              min_samples_split = 4,\n",
    "                              min_samples_leaf = 1,\n",
    "                              max_leaf_nodes = None)\n",
    "rfc1.fit(X_train, y_train)\n",
    "y_pred_rfc1_train = rfc1.predict(X_train)\n",
    "y_pred_rfc1_test = rfc1.predict(X_test)\n",
    "y_proba_rfc1_train = rfc1.predict_proba(X_train)\n",
    "y_proba_rfc1_test = rfc1.predict_proba(X_test)\n",
    "\n",
    "end_time_rfc1 = time.time()\n",
    "\n",
    "print(f\"Run Time: {end_time_rfc1 - start_time_rfc1}\")\n",
    "print(f\"Weighted F1 Score (Train): {f1_score(y_train, y_pred_rfc1_train, average = 'weighted')}\")\n",
    "print(f\"Weighted F1 Score (Test): {f1_score(y_test, y_pred_rfc1_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss (Train):  {log_loss(y_train, y_proba_rfc1_train)}\")\n",
    "print(f\"Log Loss (Test):  {log_loss(y_test, y_proba_rfc1_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e955663a-f9d9-4d3b-97b6-63109f1053c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score (Train): 0.8363684539787087\n",
      "Weighted F1 Score (Test): 0.7274706111825796\n",
      "Log Loss (Train):  0.5402181994621008\n",
      "Log Loss (Test):  0.7095042726206793\n",
      "Run Time: 347.4807481765747\n"
     ]
    }
   ],
   "source": [
    "start_time_xgb = time.time()\n",
    "\n",
    "xgb = XGBClassifier(n_estimators = 10, learning_rate = 0.29775, max_depth = 8, min_child_weight = 2, random_state = 100)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb_train = xgb.predict(X_train)\n",
    "y_pred_xgb_test = xgb.predict(X_test)\n",
    "y_proba_xgb_train = xgb.predict_proba(X_train)\n",
    "y_proba_xgb_test = xgb.predict_proba(X_test)\n",
    "\n",
    "end_time_xgb = time.time()\n",
    "\n",
    "print(f\"Weighted F1 Score (Train): {f1_score(y_train, y_pred_xgb_train, average = 'weighted')}\")\n",
    "print(f\"Weighted F1 Score (Test): {f1_score(y_test, y_pred_xgb_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss (Train):  {log_loss(y_train, y_proba_xgb_train)}\")\n",
    "print(f\"Log Loss (Test):  {log_loss(y_test, y_proba_xgb_test)}\")\n",
    "print(f\"Run Time: {end_time_xgb - start_time_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7a972324-56b8-43da-b66c-3c1a84a470b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score (Train): 0.7861715069951298\n",
      "Weighted F1 Score (Test): 0.6996941067106328\n",
      "Log Loss (Train):  0.6465076149790803\n",
      "Log Loss (Test):  0.7721565087923342\n",
      "Run Time: 191.12715482711792\n"
     ]
    }
   ],
   "source": [
    "start_time_xgb = time.time()\n",
    "\n",
    "xgb = XGBClassifier(n_estimators = 50, learning_rate = 0.29775, max_depth = 8, min_child_weight = 2, random_state = 100)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb_train = xgb.predict(X_train)\n",
    "y_pred_xgb_test = xgb.predict(X_test)\n",
    "y_proba_xgb_train = xgb.predict_proba(X_train)\n",
    "y_proba_xgb_test = xgb.predict_proba(X_test)\n",
    "\n",
    "end_time_xgb = time.time()\n",
    "\n",
    "print(f\"Weighted F1 Score (Train): {f1_score(y_train, y_pred_xgb_train, average = 'weighted')}\")\n",
    "print(f\"Weighted F1 Score (Test): {f1_score(y_test, y_pred_xgb_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss (Train):  {log_loss(y_train, y_proba_xgb_train)}\")\n",
    "print(f\"Log Loss (Test):  {log_loss(y_test, y_proba_xgb_test)}\")\n",
    "print(f\"Run Time: {end_time_xgb - start_time_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7836ba7e-9939-435b-bbe4-b3c48069b22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score (Train): 0.8363684539787087\n",
      "Weighted F1 Score (Test): 0.7274706111825796\n",
      "Log Loss (Train):  0.5402181994621008\n",
      "Log Loss (Test):  0.7095042726206793\n",
      "Run Time: 388.44012236595154\n"
     ]
    }
   ],
   "source": [
    "start_time_xgb = time.time()\n",
    "\n",
    "xgb = XGBClassifier(n_estimators = 100, learning_rate = 0.29775, max_depth = 8, min_child_weight = 2, random_state = 100)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb_train = xgb.predict(X_train)\n",
    "y_pred_xgb_test = xgb.predict(X_test)\n",
    "y_proba_xgb_train = xgb.predict_proba(X_train)\n",
    "y_proba_xgb_test = xgb.predict_proba(X_test)\n",
    "\n",
    "end_time_xgb = time.time()\n",
    "\n",
    "print(f\"Weighted F1 Score (Train): {f1_score(y_train, y_pred_xgb_train, average = 'weighted')}\")\n",
    "print(f\"Weighted F1 Score (Test): {f1_score(y_test, y_pred_xgb_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss (Train):  {log_loss(y_train, y_proba_xgb_train)}\")\n",
    "print(f\"Log Loss (Test):  {log_loss(y_test, y_proba_xgb_test)}\")\n",
    "print(f\"Run Time: {end_time_xgb - start_time_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0309b505-046e-4078-ab6a-26734ff06b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score (Train): 0.8666329393072114\n",
      "Weighted F1 Score (Test): 0.740821573576041\n",
      "Log Loss (Train):  0.4751014555525105\n",
      "Log Loss (Test):  0.6757501598639375\n",
      "Run Time: 528.4391038417816\n"
     ]
    }
   ],
   "source": [
    "start_time_xgb = time.time()\n",
    "\n",
    "xgb = XGBClassifier(n_estimators = 150, learning_rate = 0.29775, max_depth = 8, min_child_weight = 2, random_state = 100)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb_train = xgb.predict(X_train)\n",
    "y_pred_xgb_test = xgb.predict(X_test)\n",
    "y_proba_xgb_train = xgb.predict_proba(X_train)\n",
    "y_proba_xgb_test = xgb.predict_proba(X_test)\n",
    "\n",
    "end_time_xgb = time.time()\n",
    "\n",
    "print(f\"Weighted F1 Score (Train): {f1_score(y_train, y_pred_xgb_train, average = 'weighted')}\")\n",
    "print(f\"Weighted F1 Score (Test): {f1_score(y_test, y_pred_xgb_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss (Train):  {log_loss(y_train, y_proba_xgb_train)}\")\n",
    "print(f\"Log Loss (Test):  {log_loss(y_test, y_proba_xgb_test)}\")\n",
    "print(f\"Run Time: {end_time_xgb - start_time_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "74b2f90a-d6cf-47f2-a147-fe2e3797f6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score (Train): 0.979248789252413\n",
      "Weighted F1 Score (Test): 0.7687169973325381\n",
      "Log Loss (Train):  0.31491471134624954\n",
      "Log Loss (Test):  0.6881945138963503\n",
      "Run Time: 97.14397621154785\n"
     ]
    }
   ],
   "source": [
    "start_time_etc = time.time()\n",
    "\n",
    "etc = ExtraTreesClassifier(max_features = 'sqrt',\n",
    "                         max_samples = 0.5,\n",
    "                         bootstrap = True,\n",
    "                         random_state = 100)\n",
    "etc.fit(X_train, y_train)\n",
    "y_pred_etc_train = etc.predict(X_train)\n",
    "y_pred_etc_test = etc.predict(X_test)\n",
    "y_proba_etc_train = etc.predict_proba(X_train)\n",
    "y_proba_etc_test = etc.predict_proba(X_test)\n",
    "\n",
    "end_time_etc = time.time()\n",
    "\n",
    "print(f\"Weighted F1 Score (Train): {f1_score(y_train, y_pred_etc_train, average = 'weighted')}\")\n",
    "print(f\"Weighted F1 Score (Test): {f1_score(y_test, y_pred_etc_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss (Train):  {log_loss(y_train, y_proba_etc_train)}\")\n",
    "print(f\"Log Loss (Test):  {log_loss(y_test, y_proba_etc_test)}\")\n",
    "print(f\"Run Time: {end_time_etc - start_time_etc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7293c9be-cab3-4db1-acad-d6885639e984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score (Train): 0.8878741622932251\n",
      "Weighted F1 Score (Test): 0.7473048244180484\n",
      "Log Loss (Train):  0.42613900739648186\n",
      "Log Loss (Test):  0.6531871223705179\n",
      "Run Time: 1301.7270367145538\n"
     ]
    }
   ],
   "source": [
    "start_time_xgb = time.time()\n",
    "\n",
    "xgb = XGBClassifier(n_estimators = 200, learning_rate = 0.29775, max_depth = 8, min_child_weight = 2, random_state = 100)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb_train = xgb.predict(X_train)\n",
    "y_pred_xgb_test = xgb.predict(X_test)\n",
    "y_proba_xgb_train = xgb.predict_proba(X_train)\n",
    "y_proba_xgb_test = xgb.predict_proba(X_test)\n",
    "\n",
    "end_time_xgb = time.time()\n",
    "\n",
    "print(f\"Weighted F1 Score (Train): {f1_score(y_train, y_pred_xgb_train, average = 'weighted')}\")\n",
    "print(f\"Weighted F1 Score (Test): {f1_score(y_test, y_pred_xgb_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss (Train):  {log_loss(y_train, y_proba_xgb_train)}\")\n",
    "print(f\"Log Loss (Test):  {log_loss(y_test, y_proba_xgb_test)}\")\n",
    "print(f\"Run Time: {end_time_xgb - start_time_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37a5ff8a-c92a-4495-b2f0-8f2eda2d1633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score (Train): 0.905086228975606\n",
      "Weighted F1 Score (Test): 0.7540658157886949\n",
      "Log Loss (Train):  0.3878126523060198\n",
      "Log Loss (Test):  0.6383257557702969\n",
      "Run Time: 986.0501399040222\n"
     ]
    }
   ],
   "source": [
    "start_time_xgb = time.time()\n",
    "\n",
    "xgb = XGBClassifier(n_estimators = 250, learning_rate = 0.29775, max_depth = 8, min_child_weight = 2, random_state = 100)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb_train = xgb.predict(X_train)\n",
    "y_pred_xgb_test = xgb.predict(X_test)\n",
    "y_proba_xgb_train = xgb.predict_proba(X_train)\n",
    "y_proba_xgb_test = xgb.predict_proba(X_test)\n",
    "\n",
    "end_time_xgb = time.time()\n",
    "\n",
    "print(f\"Weighted F1 Score (Train): {f1_score(y_train, y_pred_xgb_train, average = 'weighted')}\")\n",
    "print(f\"Weighted F1 Score (Test): {f1_score(y_test, y_pred_xgb_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss (Train):  {log_loss(y_train, y_proba_xgb_train)}\")\n",
    "print(f\"Log Loss (Test):  {log_loss(y_test, y_proba_xgb_test)}\")\n",
    "print(f\"Run Time: {end_time_xgb - start_time_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "84ca5a17-fa58-496b-bb95-7f08836930f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score (Train): 0.9170080121344002\n",
      "Weighted F1 Score (Test): 0.7585179756516903\n",
      "Log Loss (Train):  0.3556067710529828\n",
      "Log Loss (Test):  0.6256514843201355\n",
      "Run Time: 1043.0394687652588\n"
     ]
    }
   ],
   "source": [
    "start_time_xgb = time.time()\n",
    "\n",
    "xgb = XGBClassifier(n_estimators = 300, learning_rate = 0.29775, max_depth = 8, min_child_weight = 2, random_state = 100)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb_train = xgb.predict(X_train)\n",
    "y_pred_xgb_test = xgb.predict(X_test)\n",
    "y_proba_xgb_train = xgb.predict_proba(X_train)\n",
    "y_proba_xgb_test = xgb.predict_proba(X_test)\n",
    "\n",
    "end_time_xgb = time.time()\n",
    "\n",
    "print(f\"Weighted F1 Score (Train): {f1_score(y_train, y_pred_xgb_train, average = 'weighted')}\")\n",
    "print(f\"Weighted F1 Score (Test): {f1_score(y_test, y_pred_xgb_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss (Train):  {log_loss(y_train, y_proba_xgb_train)}\")\n",
    "print(f\"Log Loss (Test):  {log_loss(y_test, y_proba_xgb_test)}\")\n",
    "print(f\"Run Time: {end_time_xgb - start_time_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "98055523-73d9-4a7a-b0aa-7d09eb380d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score (Train): 0.928884180773971\n",
      "Weighted F1 Score (Test): 0.7625226375181446\n",
      "Log Loss (Train):  0.32737022889591566\n",
      "Log Loss (Test):  0.6157804221548738\n",
      "Run Time: 1100.0064754486084\n"
     ]
    }
   ],
   "source": [
    "start_time_xgb = time.time()\n",
    "\n",
    "xgb = XGBClassifier(n_estimators = 350, learning_rate = 0.29775, max_depth = 8, min_child_weight = 2, random_state = 100)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb_train = xgb.predict(X_train)\n",
    "y_pred_xgb_test = xgb.predict(X_test)\n",
    "y_proba_xgb_train = xgb.predict_proba(X_train)\n",
    "y_proba_xgb_test = xgb.predict_proba(X_test)\n",
    "\n",
    "end_time_xgb = time.time()\n",
    "\n",
    "print(f\"Weighted F1 Score (Train): {f1_score(y_train, y_pred_xgb_train, average = 'weighted')}\")\n",
    "print(f\"Weighted F1 Score (Test): {f1_score(y_test, y_pred_xgb_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss (Train):  {log_loss(y_train, y_proba_xgb_train)}\")\n",
    "print(f\"Log Loss (Test):  {log_loss(y_test, y_proba_xgb_test)}\")\n",
    "print(f\"Run Time: {end_time_xgb - start_time_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2d2b35f9-74d3-4900-9e18-481513bfe168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score (Train): 0.9372284327543249\n",
      "Weighted F1 Score (Test): 0.7645371487927606\n",
      "Log Loss (Train):  0.3036385798768231\n",
      "Log Loss (Test):  0.6093739166162941\n",
      "Run Time: 1256.4366989135742\n"
     ]
    }
   ],
   "source": [
    "start_time_xgb = time.time()\n",
    "\n",
    "xgb = XGBClassifier(n_estimators = 400, learning_rate = 0.29775, max_depth = 8, min_child_weight = 2, random_state = 100)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb_train = xgb.predict(X_train)\n",
    "y_pred_xgb_test = xgb.predict(X_test)\n",
    "y_proba_xgb_train = xgb.predict_proba(X_train)\n",
    "y_proba_xgb_test = xgb.predict_proba(X_test)\n",
    "\n",
    "end_time_xgb = time.time()\n",
    "\n",
    "print(f\"Weighted F1 Score (Train): {f1_score(y_train, y_pred_xgb_train, average = 'weighted')}\")\n",
    "print(f\"Weighted F1 Score (Test): {f1_score(y_test, y_pred_xgb_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss (Train):  {log_loss(y_train, y_proba_xgb_train)}\")\n",
    "print(f\"Log Loss (Test):  {log_loss(y_test, y_proba_xgb_test)}\")\n",
    "print(f\"Run Time: {end_time_xgb - start_time_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e7a2368-3bb0-44ab-8f68-ace83c768b11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted F1 Score (Train): 0.9516040046818818\n",
      "Weighted F1 Score (Test): 0.7666405882305194\n",
      "Log Loss (Train):  0.26181900007080255\n",
      "Log Loss (Test):  0.6002008883437594\n",
      "Run Time: 1566.1028113365173\n"
     ]
    }
   ],
   "source": [
    "start_time_xgb = time.time()\n",
    "\n",
    "xgb = XGBClassifier(n_estimators = 500, learning_rate = 0.29775, max_depth = 8, min_child_weight = 2, random_state = 100)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb_train = xgb.predict(X_train)\n",
    "y_pred_xgb_test = xgb.predict(X_test)\n",
    "y_proba_xgb_train = xgb.predict_proba(X_train)\n",
    "y_proba_xgb_test = xgb.predict_proba(X_test)\n",
    "\n",
    "end_time_xgb = time.time()\n",
    "\n",
    "print(f\"Weighted F1 Score (Train): {f1_score(y_train, y_pred_xgb_train, average = 'weighted')}\")\n",
    "print(f\"Weighted F1 Score (Test): {f1_score(y_test, y_pred_xgb_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss (Train):  {log_loss(y_train, y_proba_xgb_train)}\")\n",
    "print(f\"Log Loss (Test):  {log_loss(y_test, y_proba_xgb_test)}\")\n",
    "print(f\"Run Time: {end_time_xgb - start_time_xgb}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bd74d6-d472-4efa-ae0a-28e495306e03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
