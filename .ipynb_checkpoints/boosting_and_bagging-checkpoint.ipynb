{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ab19f08-c0c3-4c93-a9d2-13574aa0c7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "from preprocessor_class import Preprocessor\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score, log_loss\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6b13719-cacc-4810-807c-829e7cd45942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/prepared_text_data_sugar.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2959e97-73c1-471f-86d3-bc4789b75488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Runtime:  27.266846656799316\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>abso</th>\n",
       "      <th>absolut</th>\n",
       "      <th>abv</th>\n",
       "      <th>acai</th>\n",
       "      <th>accompani</th>\n",
       "      <th>ace</th>\n",
       "      <th>acha</th>\n",
       "      <th>acqua</th>\n",
       "      <th>ad</th>\n",
       "      <th>...</th>\n",
       "      <th>zinfidel</th>\n",
       "      <th>zing</th>\n",
       "      <th>zinger</th>\n",
       "      <th>ziti</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zt</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zuppa</th>\n",
       "      <th>íleaf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42339</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42340</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42341</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42342</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42343</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42344 rows × 4005 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        aa  abso  absolut  abv  acai  accompani  ace  acha  acqua   ad  ...  \\\n",
       "0      0.0   0.0      0.0  0.0   0.0        0.0  0.0   0.0    0.0  0.0  ...   \n",
       "1      0.0   0.0      0.0  0.0   0.0        0.0  0.0   0.0    0.0  0.0  ...   \n",
       "2      0.0   0.0      0.0  0.0   0.0        0.0  0.0   0.0    0.0  0.0  ...   \n",
       "3      0.0   0.0      0.0  0.0   0.0        0.0  0.0   0.0    0.0  0.0  ...   \n",
       "4      0.0   0.0      0.0  0.0   0.0        0.0  0.0   0.0    0.0  0.0  ...   \n",
       "...    ...   ...      ...  ...   ...        ...  ...   ...    ...  ...  ...   \n",
       "42339  0.0   0.0      0.0  0.0   0.0        0.0  0.0   0.0    0.0  0.0  ...   \n",
       "42340  0.0   0.0      0.0  0.0   0.0        0.0  0.0   0.0    0.0  0.0  ...   \n",
       "42341  0.0   0.0      0.0  0.0   0.0        0.0  0.0   0.0    0.0  0.0  ...   \n",
       "42342  0.0   0.0      0.0  0.0   0.0        0.0  0.0   0.0    0.0  0.0  ...   \n",
       "42343  0.0   0.0      0.0  0.0   0.0        0.0  0.0   0.0    0.0  0.0  ...   \n",
       "\n",
       "       zinfidel  zing  zinger  ziti  zombi  zone   zt  zucchini  zuppa  íleaf  \n",
       "0           0.0   0.0     0.0   0.0    0.0   0.0  0.0       0.0    0.0    0.0  \n",
       "1           0.0   0.0     0.0   0.0    0.0   0.0  0.0       0.0    0.0    0.0  \n",
       "2           0.0   0.0     0.0   0.0    0.0   0.0  0.0       0.0    0.0    0.0  \n",
       "3           0.0   0.0     0.0   0.0    0.0   0.0  0.0       0.0    0.0    0.0  \n",
       "4           0.0   0.0     0.0   0.0    0.0   0.0  0.0       0.0    0.0    0.0  \n",
       "...         ...   ...     ...   ...    ...   ...  ...       ...    ...    ...  \n",
       "42339       0.0   0.0     0.0   0.0    0.0   0.0  0.0       0.0    0.0    0.0  \n",
       "42340       0.0   0.0     0.0   0.0    0.0   0.0  0.0       0.0    0.0    0.0  \n",
       "42341       0.0   0.0     0.0   0.0    0.0   0.0  0.0       0.0    0.0    0.0  \n",
       "42342       0.0   0.0     0.0   0.0    0.0   0.0  0.0       0.0    0.0    0.0  \n",
       "42343       0.0   0.0     0.0   0.0    0.0   0.0  0.0       0.0    0.0    0.0  \n",
       "\n",
       "[42344 rows x 4005 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time_preprocess = time.time()\n",
    "\n",
    "X = df['text']\n",
    "y = df['sugar_class']\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 200)\n",
    "processor = Preprocessor()\n",
    "X_train_transformed = processor.fit_transform(X_train_raw)\n",
    "X_test_transformed = processor.transform(X_test_raw)\n",
    "\n",
    "vector_pipe = Pipeline([('tfidf', TfidfVectorizer())])\n",
    "X_train_vector = vector_pipe.fit_transform(X_train_transformed)\n",
    "X_test_vector = vector_pipe.transform(X_test_transformed)\n",
    "X_train = pd.DataFrame(X_train_vector.toarray(), columns = vector_pipe['tfidf'].get_feature_names())\n",
    "X_test = pd.DataFrame(X_test_vector.toarray(), columns = vector_pipe['tfidf'].get_feature_names())\n",
    "\n",
    "end_time_preprocess = time.time()\n",
    "preprocess_time = end_time_preprocess - start_time_preprocess\n",
    "\n",
    "print(f\"Preprocessing Runtime:  {preprocess_time}\")\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b717a4a6-735d-4b8d-82e1-f24732c9b6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive-Bayes Runtime:  3.89 seconds\n",
      "\n",
      "Weighted F1 Score, Multinomial NB Train: 0.6296011066073247\n",
      "Log Loss, Multinomial NB Train:  0.9319198344350808\n",
      "Weighted F1 Score, Multinomial NB Test: 0.602859353334295\n",
      "Log Loss, Multinomial NB Test:  0.9698460540526268\n",
      "\n",
      "Weighted F1 Score, Complement NB Train: 0.631216626696921\n",
      "Log Loss, Complement NB Train:  1.1299313090432557\n",
      "Weighted F1 Score, Complement NB Test: 0.594470343461912\n",
      "Log Loss, Complement NB Test:  1.1593542368287353\n"
     ]
    }
   ],
   "source": [
    "start_time_nb = time.time()\n",
    "\n",
    "multinb = Pipeline([('multinb', MultinomialNB())])\n",
    "multinb.fit(X_train, y_train)\n",
    "y_pred_baseline_train = multinb.predict(X_train)\n",
    "y_pred_baseline_test = multinb.predict(X_test)\n",
    "y_proba_baseline_train = multinb.predict_proba(X_train)\n",
    "y_proba_baseline_test = multinb.predict_proba(X_test)\n",
    "\n",
    "compnb = Pipeline([('compnb', ComplementNB())])\n",
    "compnb.fit(X_train, y_train)\n",
    "y_pred_compnb_train = compnb.predict(X_train)\n",
    "y_pred_compnb_test = compnb.predict(X_test)\n",
    "y_proba_compnb_train = compnb.predict_proba(X_train)\n",
    "y_proba_compnb_test = compnb.predict_proba(X_test)\n",
    "\n",
    "end_time_nb = time.time()\n",
    "nb_time = end_time_nb - start_time_nb\n",
    "\n",
    "print(f\"Naive-Bayes Runtime:  {nb_time:.2f} seconds\")\n",
    "print(\"\")\n",
    "print(f\"Weighted F1 Score, Multinomial NB Train: {f1_score(y_train, y_pred_baseline_train, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Multinomial NB Train:  {log_loss(y_train, y_proba_baseline_train)}\")\n",
    "print(f\"Weighted F1 Score, Multinomial NB Test: {f1_score(y_test, y_pred_baseline_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Multinomial NB Test:  {log_loss(y_test, y_proba_baseline_test)}\")\n",
    "print(\"\")\n",
    "print(f\"Weighted F1 Score, Complement NB Train: {f1_score(y_train, y_pred_compnb_train, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Complement NB Train:  {log_loss(y_train, y_proba_compnb_train)}\")\n",
    "print(f\"Weighted F1 Score, Complement NB Test: {f1_score(y_test, y_pred_compnb_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Complement NB Test:  {log_loss(y_test, y_proba_compnb_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d53c3f06-b757-4112-b355-a95eb545817c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Runtime:  214.59 seconds\n",
      "\n",
      "Weighted F1 Score, AdaBoost Train: 0.5291930608118532\n",
      "Log Loss, AdaBoost Train:  1.557688314123807\n",
      "Weighted F1 Score, AdaBoost Test: 0.5303689962703744\n",
      "Log Loss, AdaBoost Test:  1.5596262938722978\n"
     ]
    }
   ],
   "source": [
    "start_time_ada = time.time()\n",
    "\n",
    "ada = Pipeline([('ada', AdaBoostClassifier())])\n",
    "ada.fit(X_train, y_train)\n",
    "y_pred_ada_train = ada.predict(X_train)\n",
    "y_pred_ada_test = ada.predict(X_test)\n",
    "y_proba_ada_train = ada.predict_proba(X_train)\n",
    "y_proba_ada_test = ada.predict_proba(X_test)\n",
    "\n",
    "end_time_ada = time.time()\n",
    "ada_time = end_time_ada - start_time_ada\n",
    "\n",
    "print(f\"AdaBoost Runtime:  {ada_time:.2f} seconds\")\n",
    "print(\"\")\n",
    "print(f\"Weighted F1 Score, AdaBoost Train: {f1_score(y_train, y_pred_ada_train, average = 'weighted')}\")\n",
    "print(f\"Log Loss, AdaBoost Train:  {log_loss(y_train, y_proba_ada_train)}\")\n",
    "print(f\"Weighted F1 Score, AdaBoost Test: {f1_score(y_test, y_pred_ada_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss, AdaBoost Test:  {log_loss(y_test, y_proba_ada_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e41aaca0-273f-420b-9954-59e5f54d55c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Runtime:  196.12 seconds\n",
      "\n",
      "Weighted F1 Score, Random Forest Train: 0.9854428498834271\n",
      "Log Loss, Random Forest Train:  0.2236946141191958\n",
      "Weighted F1 Score, Random Forest Test: 0.7819321911037243\n",
      "Log Loss, Random Forest Test:  0.6277176649319787\n"
     ]
    }
   ],
   "source": [
    "start_time_rfc = time.time()\n",
    "\n",
    "rfc = Pipeline([('rfc', RandomForestClassifier(n_estimators = 200,\n",
    "                                              criterion = 'gini',\n",
    "                                              max_depth = None,\n",
    "                                              min_samples_split = 4,\n",
    "                                              min_samples_leaf = 1,\n",
    "                                              max_leaf_nodes = None,\n",
    "                                              max_samples = None,\n",
    "                                              random_state = 200))])\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred_rfc_train = rfc.predict(X_train)\n",
    "y_pred_rfc_test = rfc.predict(X_test)\n",
    "y_proba_rfc_train = rfc.predict_proba(X_train)\n",
    "y_proba_rfc_test = rfc.predict_proba(X_test)\n",
    "\n",
    "end_time_rfc = time.time()\n",
    "rfc_time = end_time_rfc - start_time_rfc\n",
    "\n",
    "print(f\"Random Forest Runtime:  {rfc_time:.2f} seconds\")\n",
    "print(\"\")\n",
    "print(f\"Weighted F1 Score, Random Forest Train: {f1_score(y_train, y_pred_rfc_train, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Random Forest Train:  {log_loss(y_train, y_proba_rfc_train)}\")\n",
    "print(f\"Weighted F1 Score, Random Forest Test: {f1_score(y_test, y_pred_rfc_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Random Forest Test:  {log_loss(y_test, y_proba_rfc_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d183287a-896e-4d80-a362-fafe4740cdbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Runtime:  1758.27 seconds\n",
      "\n",
      "Weighted F1 Score, XGB Train: 0.9477228463965388\n",
      "Log Loss, XGB Train:  0.27168454377174867\n",
      "Weighted F1 Score, XGB Test: 0.7795149067683812\n",
      "Log Loss, XGB Test:  0.5828199685655608\n"
     ]
    }
   ],
   "source": [
    "start_time_xgb = time.time()\n",
    "\n",
    "xgb = Pipeline([('xgb', XGBClassifier(n_estimators = 500,\n",
    "              learning_rate = 0.29775,\n",
    "              max_depth = 8,\n",
    "              min_child_weight = 2,\n",
    "              random_state = 100))])\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb_train = xgb.predict(X_train)\n",
    "y_pred_xgb_test = xgb.predict(X_test)\n",
    "y_proba_xgb_train = xgb.predict_proba(X_train)\n",
    "y_proba_xgb_test = xgb.predict_proba(X_test)\n",
    "\n",
    "end_time_xgb = time.time()\n",
    "xgb_time = end_time_xgb - start_time_xgb\n",
    "\n",
    "print(f\"XGB Runtime:  {xgb_time:.2f} seconds\")\n",
    "print(\"\")\n",
    "print(f\"Weighted F1 Score, XGB Train: {f1_score(y_train, y_pred_xgb_train, average = 'weighted')}\")\n",
    "print(f\"Log Loss, XGB Train:  {log_loss(y_train, y_proba_xgb_train)}\")\n",
    "print(f\"Weighted F1 Score, XGB Test: {f1_score(y_test, y_pred_xgb_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss, XGB Test:  {log_loss(y_test, y_proba_xgb_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84f67ae3-30d3-4386-bf41-2572d7922849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees Runtime:  400.37 seconds\n",
      "\n",
      "Weighted F1 Score, Extra Trees Train: 0.9814200136427785\n",
      "Log Loss, Extra Trees Train:  0.3060257050998168\n",
      "Weighted F1 Score, Extra Trees Test: 0.7804834437494838\n",
      "Log Loss, Extra Trees Test:  0.6396806810788392\n"
     ]
    }
   ],
   "source": [
    "start_time_etc = time.time()\n",
    "\n",
    "etc = Pipeline([('etc', ExtraTreesClassifier(n_estimators = 400,\n",
    "                                             max_features = 'sqrt',\n",
    "                                             max_samples = 0.5,\n",
    "                                             bootstrap = True,\n",
    "                                             random_state = 200))])\n",
    "etc.fit(X_train, y_train)\n",
    "y_pred_etc_train = etc.predict(X_train)\n",
    "y_pred_etc_test = etc.predict(X_test)\n",
    "y_proba_etc_train = etc.predict_proba(X_train)\n",
    "y_proba_etc_test = etc.predict_proba(X_test)\n",
    "\n",
    "end_time_etc = time.time()\n",
    "etc_time = end_time_etc - start_time_etc\n",
    "\n",
    "print(f\"Extra Trees Runtime:  {etc_time:.2f} seconds\")\n",
    "print(\"\")\n",
    "print(f\"Weighted F1 Score, Extra Trees Train: {f1_score(y_train, y_pred_etc_train, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Extra Trees Train:  {log_loss(y_train, y_proba_etc_train)}\")\n",
    "print(f\"Weighted F1 Score, Extra Trees Test: {f1_score(y_test, y_pred_etc_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Extra Trees Test:  {log_loss(y_test, y_proba_etc_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9993c35d-4b8a-42b6-aa24-2ab6d3948563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Voting Classifier Runtime:  4174.52 seconds\n",
      "\n",
      "Weighted F1 Score, Average Voting Classifier Train: 0.9813963644952933\n",
      "Log Loss, Average Voting Classifier Train:  0.2716736212586663\n",
      "Weighted F1 Score, Average Voting Classifier Test: 0.7957843884139046\n",
      "Log Loss, Average Voting Classifier Test:  0.5959754064663629\n"
     ]
    }
   ],
   "source": [
    "start_time_avg = time.time()\n",
    "\n",
    "avg = VotingClassifier(estimators = [('rfc', rfc),\n",
    "                                     ('xgb', xgb),\n",
    "                                     ('etc', etc)],\n",
    "                                     weights = [0.25, 0.25, 0.5],\n",
    "                                     voting = 'soft')\n",
    "avg.fit(X_train, y_train)\n",
    "y_pred_avg_train = avg.predict(X_train)\n",
    "y_pred_avg_test = avg.predict(X_test)\n",
    "y_proba_avg_train = avg.predict_proba(X_train)\n",
    "y_proba_avg_test = avg.predict_proba(X_test)\n",
    "\n",
    "end_time_avg = time.time()\n",
    "avg_time = end_time_avg - start_time_avg\n",
    "\n",
    "print(f\"Average Voting Classifier Runtime:  {avg_time:.2f} seconds\")\n",
    "print(\"\")\n",
    "print(f\"Weighted F1 Score, Average Voting Classifier Train: {f1_score(y_train, y_pred_avg_train, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Average Voting Classifier Train:  {log_loss(y_train, y_proba_avg_train)}\")\n",
    "print(f\"Weighted F1 Score, Average Voting Classifier Test: {f1_score(y_test, y_pred_avg_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Average Voting Classifier Test:  {log_loss(y_test, y_proba_avg_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e02f2b5-f393-4679-a4a5-cc6813031e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Runtime:  4174.52 seconds\n",
      "\n",
      "Weighted F1 Score, Stacking Classifier Train: 0.9742016514410242\n",
      "Log Loss, Stacking Classifier Train:  0.18996482630955172\n",
      "Weighted F1 Score, Stacking Classifier Test: 0.7969076234123531\n",
      "Log Loss, Stacking Classifier Test:  0.5742685261226821\n"
     ]
    }
   ],
   "source": [
    "start_time_stack = time.time()\n",
    "\n",
    "estimators = [('rfc', rfc),\n",
    "              ('xgb', xgb)]\n",
    "              #('etc', etc)]\n",
    "\n",
    "stack_clf = StackingClassifier(estimators = estimators,\n",
    "                               final_estimator = etc)\n",
    "stack_clf.fit(X_train, y_train)\n",
    "y_pred_stack_train = stack_clf.predict(X_train)\n",
    "y_pred_stack_test = stack_clf.predict(X_test)\n",
    "y_proba_stack_train = stack_clf.predict_proba(X_train)\n",
    "y_proba_stack_test = stack_clf.predict_proba(X_test)\n",
    "\n",
    "end_time_stack = time.time()\n",
    "stack_time = end_time_stack - start_time_stack\n",
    "\n",
    "print(f\"Stacking Classifier Runtime:  {stack_time:.2f} seconds\")\n",
    "print(\"\")\n",
    "print(f\"Weighted F1 Score, Stacking Classifier Train: {f1_score(y_train, y_pred_stack_train, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Stacking Classifier Train:  {log_loss(y_train, y_proba_stack_train)}\")\n",
    "print(f\"Weighted F1 Score, Stacking Classifier Test: {f1_score(y_test, y_pred_stack_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Stacking Classifier Test:  {log_loss(y_test, y_proba_stack_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f3b9df3-f6df-4603-b891-656edc4ec67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Runtime:  321.99 minutes\n"
     ]
    }
   ],
   "source": [
    "print(f\"Stacking Classifier Runtime:  {stack_time / 60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bd2595-344f-41b0-b975-087533301e86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
