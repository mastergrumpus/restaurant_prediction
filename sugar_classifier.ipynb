{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc04295-fea8-4848-8428-013219884af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import time\n",
    "import random\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier, BaggingClassifier, VotingClassifier, ExtraTreesClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score, log_loss\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Input, Dropout, LeakyReLU\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fe248d-9116-4946-822f-86235e3207db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sugar_classifier(sugar):\n",
    "    if sugar >= 30:\n",
    "        return 5\n",
    "    elif (sugar < 30) & (sugar >= 7):\n",
    "        return 4\n",
    "    elif (sugar < 7) & (sugar > 2):\n",
    "        return 3\n",
    "    elif (sugar <= 2) & (sugar > 0):\n",
    "        return 2\n",
    "    elif sugar == 0:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b485ac-674e-4d94-83a3-e1fa805146b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "\n",
    "class Preprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, data, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, data, y=None):\n",
    "        preprocessed_data = [self.stem_doc(doc) for doc in data]\n",
    "        return preprocessed_data\n",
    "\n",
    "    def stem_doc(self, doc):\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        lower_doc = [token.lower() for token in word_tokenize(doc) if token.isalpha()]\n",
    "        filtered_doc = [token for token in lower_doc if token not in stop_words]\n",
    "        stemmed_doc = [stemmer.stem(token) for token in filtered_doc]\n",
    "        return \" \".join(stemmed_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c67f8f-d953-43ff-9894-d00638ef3d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_read = time.time()\n",
    "\n",
    "df_raw = pd.read_csv('Data/menu_items.csv', low_memory = False)\n",
    "relevant_columns = ['Restaurant_Item_Name', 'restaurant', 'Item_Name', 'Item_Description', 'Food_Category', 'Sugar']\n",
    "df_relevant = df_raw.loc[:, relevant_columns]\n",
    "df_relevant.dropna(inplace = True)\n",
    "df = df_relevant.sort_values(by = 'Sugar', ascending = False)\n",
    "df = df.reset_index(drop = True)\n",
    "df['sugar_class'] = df['Sugar'].apply(sugar_classifier)\n",
    "\n",
    "end_time_read = time.time()\n",
    "read_time = end_time_read - start_time_read\n",
    "\n",
    "print(f\"Data Reading Runtime:  {read_time:.2f} seconds\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6f2c1-ed15-4de7-bf0d-54f7a3c28e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = df['restaurant'].value_counts()\n",
    "for value, count in value_counts.items():\n",
    "    print(f'{value}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c3bbb2-b9ea-44c8-b499-31bd450d57e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_clean = time.time()\n",
    "\n",
    "df['text'] = df['Restaurant_Item_Name'] + \" \" + df['Item_Name'] + \" \" + df['Item_Description'] + \" \" + df['Food_Category']\n",
    "df.drop(columns = ['Restaurant_Item_Name', 'Item_Name', 'Item_Description', 'Food_Category', 'Sugar'], inplace = True)\n",
    "df['restaurant'] = df['restaurant'].str.split()\n",
    "for index, row in df.iterrows():\n",
    "    for string in row['restaurant']:\n",
    "        df.at[index, 'text'] = df.at[index, 'text'].replace(string, '')\n",
    "df.drop(columns = 'restaurant', inplace = True)\n",
    "\n",
    "end_time_clean = time.time()\n",
    "clean_time = end_time_clean - start_time_clean\n",
    "\n",
    "print(f\"Data Cleaning Runtime:  {clean_time:.2f} seconds\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad992e79-a188-4b48-a1c6-3023e9e13fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('prepared_text_data_sugar.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3f124b-87e4-4964-8c64-e44c273321e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['text']\n",
    "y = data['sugar_class']\n",
    "\n",
    "#One-Hot_Encoding target variable, train/test split\n",
    "ohe = OneHotEncoder(drop='first', sparse=False)\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X, y, test_size = 0.2, random_state = 200)\n",
    "y_train_raw = y_train_raw.values.reshape(-1, 1)\n",
    "y_test_raw = y_test_raw.values.reshape(-1, 1)\n",
    "y_train = ohe.fit_transform(y_train_raw - 1)\n",
    "y_test = ohe.transform(y_test_raw - 1)\n",
    "\n",
    "#Pre-processing and vectorizing text\n",
    "processor = Preprocessor()\n",
    "X_train_transformed = processor.fit_transform(X_train_raw)\n",
    "X_test_transformed = processor.transform(X_test_raw)\n",
    "vector_pipe = Pipeline([('tfidf', TfidfVectorizer())])\n",
    "X_train_vector = vector_pipe.fit_transform(X_train_transformed)\n",
    "X_test_vector = vector_pipe.transform(X_test_transformed)\n",
    "\n",
    "#Returning independent variables to pd.Dataframe\n",
    "X_train = pd.DataFrame(X_train_vector.toarray(), columns = vector_pipe['tfidf'].get_feature_names())\n",
    "X_test = pd.DataFrame(X_test_vector.toarray(), columns = vector_pipe['tfidf'].get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b1b262-ce4d-47d4-8eda-72ab89894118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensuring X_train and X_test are proper data types\n",
    "X_train_array = X_train.values if isinstance(X_train, pd.DataFrame) else X_train\n",
    "X_test_array = X_test.values if isinstance(X_test, pd.DataFrame) else X_test\n",
    "\n",
    "#\n",
    "y_train_reshaped = np.argmax(y_train_encoded, axis=2)\n",
    "\n",
    "#\n",
    "def f1_metric(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    true_positives = tf.reduce_sum(tf.cast(y_true * y_pred, tf.float32), axis=0)\n",
    "    predicted_positives = tf.reduce_sum(tf.cast(y_pred, tf.float32), axis=0)\n",
    "    actual_positives = tf.reduce_sum(tf.cast(y_true, tf.float32), axis=0)\n",
    "    precision = true_positives / (predicted_positives + tf.keras.backend.epsilon())\n",
    "    recall = true_positives / (actual_positives + tf.keras.backend.epsilon())\n",
    "    \n",
    "    f1 = 2 * precision * recall / (precision + recall + tf.keras.backend.epsilon())\n",
    "    return tf.reduce_mean(f1)\n",
    "\n",
    "#\n",
    "trainCallback = EarlyStopping(monitor='loss', min_delta = 1e-6, patience = 5)\n",
    "\n",
    "reg = l2(0.0001)\n",
    "opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1485fb11-4c28-43d0-bf04-211bf908540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1800, activation = LeakyReLU(), input_shape = (X_train_array.shape[1],), kernel_regularizer = reg))\n",
    "model.add(Dense(4, activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = opt, metrics = [f1_metric])\n",
    "model.fit(X_train_array, y_train_reshaped, epochs = 15, callbacks=[trainCallback], batch_size= 128, validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317d8fc0-5061-4a98-bc69-c207f9d56493",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_preprocess = time.time()\n",
    "\n",
    "X = df['text']\n",
    "y = df['sugar_class']\n",
    "\n",
    "X_train_raw, X_test_raw, y_train_raw, y_test_raw = train_test_split(X, y, test_size = 0.2, random_state = 200)\n",
    "processor = Preprocessor()\n",
    "X_train_transformed = processor.fit_transform(X_train_raw)\n",
    "X_test_transformed = processor.transform(X_test_raw)\n",
    "\n",
    "vector_pipe = Pipeline([('tfidf', TfidfVectorizer())])\n",
    "X_train_vector = vector_pipe.fit_transform(X_train_transformed)\n",
    "X_test_vector = vector_pipe.transform(X_test_transformed)\n",
    "X_train = pd.DataFrame(X_train_vector.toarray(), columns = vector_pipe['tfidf'].get_feature_names())\n",
    "X_test = pd.DataFrame(X_test_vector.toarray(), columns = vector_pipe['tfidf'].get_feature_names())\n",
    "\n",
    "end_time_preprocess = time.time()\n",
    "preprocess_time = end_time_preprocess - start_time_preprocess\n",
    "\n",
    "print(f\"Preprocessing Runtime:  {preprocess_time}\")\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c608e7-7ff3-4ff6-bca6-a57b31046489",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_nb = time.time()\n",
    "\n",
    "multinb = Pipeline([('multinb', MultinomialNB())])\n",
    "multinb.fit(X_train, y_train)\n",
    "y_pred_baseline_train = multinb.predict(X_train)\n",
    "y_pred_baseline_test = multinb.predict(X_test)\n",
    "y_proba_baseline_train = multinb.predict_proba(X_train)\n",
    "y_proba_baseline_test = multinb.predict_proba(X_test)\n",
    "\n",
    "compnb = Pipeline([('compnb', ComplementNB())])\n",
    "compnb.fit(X_train, y_train)\n",
    "y_pred_compnb_train = compnb.predict(X_train)\n",
    "y_pred_compnb_test = compnb.predict(X_test)\n",
    "y_proba_compnb_train = compnb.predict_proba(X_train)\n",
    "y_proba_compnb_test = compnb.predict_proba(X_test)\n",
    "\n",
    "end_time_nb = time.time()\n",
    "nb_time = end_time_nb - start_time_nb\n",
    "\n",
    "print(f\"Naive-Bayes Runtime:  {nb_time:.2f} seconds\")\n",
    "print(\"\")\n",
    "print(f\"Weighted F1 Score, Multinomial NB Train: {f1_score(y_train, y_pred_baseline_train, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Multinomial NB Train:  {log_loss(y_train, y_proba_baseline_train)}\")\n",
    "print(f\"Weighted F1 Score, Multinomial NB Test: {f1_score(y_test, y_pred_baseline_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Multinomial NB Test:  {log_loss(y_test, y_proba_baseline_test)}\")\n",
    "print(\"\")\n",
    "print(f\"Weighted F1 Score, Complement NB Train: {f1_score(y_train, y_pred_compnb_train, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Complement NB Train:  {log_loss(y_train, y_proba_compnb_train)}\")\n",
    "print(f\"Weighted F1 Score, Complement NB Test: {f1_score(y_test, y_pred_compnb_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Complement NB Test:  {log_loss(y_test, y_proba_compnb_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ac3f4-9f2a-4974-b9f9-a16e4b6fc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_ada = time.time()\n",
    "\n",
    "ada = Pipeline([('ada', AdaBoostClassifier())])\n",
    "ada.fit(X_train, y_train)\n",
    "y_pred_ada_train = ada.predict(X_train)\n",
    "y_pred_ada_test = ada.predict(X_test)\n",
    "y_proba_ada_train = ada.predict_proba(X_train)\n",
    "y_proba_ada_test = ada.predict_proba(X_test)\n",
    "\n",
    "end_time_ada = time.time()\n",
    "ada_time = end_time_ada - start_time_ada\n",
    "\n",
    "print(f\"AdaBoost Runtime:  {ada_time:.2f} seconds\")\n",
    "print(\"\")\n",
    "print(f\"Weighted F1 Score, AdaBoost Train: {f1_score(y_train, y_pred_ada_train, average = 'weighted')}\")\n",
    "print(f\"Log Loss, AdaBoost Train:  {log_loss(y_train, y_proba_ada_train)}\")\n",
    "print(f\"Weighted F1 Score, AdaBoost Test: {f1_score(y_test, y_pred_ada_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss, AdaBoost Test:  {log_loss(y_test, y_proba_ada_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da6ca9-f2f8-4878-b33b-4c47aeb7f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_rfc = time.time()\n",
    "\n",
    "rfc = Pipeline([('rfc', RandomForestClassifier(n_estimators = 200,\n",
    "                                              criterion = 'gini',\n",
    "                                              max_depth = None,\n",
    "                                              min_samples_split = 4,\n",
    "                                              min_samples_leaf = 1,\n",
    "                                              max_leaf_nodes = None,\n",
    "                                              max_samples = None,\n",
    "                                              random_state = 200))])\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred_rfc_train = rfc.predict(X_train)\n",
    "y_pred_rfc_test = rfc.predict(X_test)\n",
    "y_proba_rfc_train = rfc.predict_proba(X_train)\n",
    "y_proba_rfc_test = rfc.predict_proba(X_test)\n",
    "\n",
    "end_time_rfc = time.time()\n",
    "rfc_time = end_time_rfc - start_time_rfc\n",
    "\n",
    "print(f\"Random Forest Runtime:  {rfc_time:.2f} seconds\")\n",
    "print(\"\")\n",
    "print(f\"Weighted F1 Score, Random Forest Train: {f1_score(y_train, y_pred_rfc_train, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Random Forest Train:  {log_loss(y_train, y_proba_rfc_train)}\")\n",
    "print(f\"Weighted F1 Score, Random Forest Test: {f1_score(y_test, y_pred_rfc_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Random Forest Test:  {log_loss(y_test, y_proba_rfc_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7164b4-a416-4ca5-8fc8-34c4e0a6bee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_xgb = time.time()\n",
    "\n",
    "xgb = Pipeline([('xgb', XGBClassifier(n_estimators = 500,\n",
    "              learning_rate = 0.29775,\n",
    "              max_depth = 8,\n",
    "              min_child_weight = 2,\n",
    "              random_state = 100))])\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb_train = xgb.predict(X_train)\n",
    "y_pred_xgb_test = xgb.predict(X_test)\n",
    "y_proba_xgb_train = xgb.predict_proba(X_train)\n",
    "y_proba_xgb_test = xgb.predict_proba(X_test)\n",
    "\n",
    "end_time_xgb = time.time()\n",
    "xgb_time = end_time_xgb - start_time_xgb\n",
    "\n",
    "print(f\"XGB Runtime:  {xgb_time:.2f} seconds\")\n",
    "print(\"\")\n",
    "print(f\"Weighted F1 Score, XGB Train: {f1_score(y_train, y_pred_xgb_train, average = 'weighted')}\")\n",
    "print(f\"Log Loss, XGB Train:  {log_loss(y_train, y_proba_xgb_train)}\")\n",
    "print(f\"Weighted F1 Score, XGB Test: {f1_score(y_test, y_pred_xgb_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss, XGB Test:  {log_loss(y_test, y_proba_xgb_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b2fdbe-7600-47fc-958a-8854183f0a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_etc = time.time()\n",
    "\n",
    "etc = Pipeline([('etc', ExtraTreesClassifier(n_estimators = 400,\n",
    "                                             max_features = 'sqrt',\n",
    "                                             max_samples = 0.5,\n",
    "                                             bootstrap = True,\n",
    "                                             random_state = 200))])\n",
    "etc.fit(X_train, y_train)\n",
    "y_pred_etc_train = etc.predict(X_train)\n",
    "y_pred_etc_test = etc.predict(X_test)\n",
    "y_proba_etc_train = etc.predict_proba(X_train)\n",
    "y_proba_etc_test = etc.predict_proba(X_test)\n",
    "\n",
    "end_time_etc = time.time()\n",
    "etc_time = end_time_etc - start_time_etc\n",
    "\n",
    "print(f\"Extra Trees Runtime:  {etc_time:.2f} seconds\")\n",
    "print(\"\")\n",
    "print(f\"Weighted F1 Score, Extra Trees Train: {f1_score(y_train, y_pred_etc_train, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Extra Trees Train:  {log_loss(y_train, y_proba_etc_train)}\")\n",
    "print(f\"Weighted F1 Score, Extra Trees Test: {f1_score(y_test, y_pred_etc_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Extra Trees Test:  {log_loss(y_test, y_proba_etc_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36300b5d-2e77-4560-95f4-87b4bb68d2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_avg = time.time()\n",
    "\n",
    "avg = VotingClassifier(estimators = [('rfc', rfc),\n",
    "                                     ('xgb', xgb),\n",
    "                                     ('etc', etc)],\n",
    "                                     weights = [0.25, 0.25, 0.5],\n",
    "                                     voting = 'soft')\n",
    "avg.fit(X_train, y_train)\n",
    "y_pred_avg_train = avg.predict(X_train)\n",
    "y_pred_avg_test = avg.predict(X_test)\n",
    "y_proba_avg_train = avg.predict_proba(X_train)\n",
    "y_proba_avg_test = avg.predict_proba(X_test)\n",
    "\n",
    "end_time_avg = time.time()\n",
    "avg_time = end_time_avg - start_time_avg\n",
    "\n",
    "print(f\"Average Voting Classifier Runtime:  {avg_time:.2f} seconds\")\n",
    "print(\"\")\n",
    "print(f\"Weighted F1 Score, Average Voting Classifier Train: {f1_score(y_train, y_pred_avg_train, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Average Voting Classifier Train:  {log_loss(y_train, y_proba_avg_train)}\")\n",
    "print(f\"Weighted F1 Score, Average Voting Classifier Test: {f1_score(y_test, y_pred_avg_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Average Voting Classifier Test:  {log_loss(y_test, y_proba_avg_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e286b67-fed7-42bd-a910-88fa6af31b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_stack = time.time()\n",
    "\n",
    "estimators = [('rfc', rfc),\n",
    "              ('xgb', xgb)]\n",
    "              #('etc', etc)]\n",
    "\n",
    "stack_clf = StackingClassifier(estimators = estimators,\n",
    "                               final_estimator = etc)\n",
    "stack_clf.fit(X_train, y_train)\n",
    "y_pred_stack_train = stack_clf.predict(X_train)\n",
    "y_pred_stack_test = stack_clf.predict(X_test)\n",
    "y_proba_stack_train = stack_clf.predict_proba(X_train)\n",
    "y_proba_stack_test = stack_clf.predict_proba(X_test)\n",
    "\n",
    "end_time_stack = time.time()\n",
    "stack_time = end_time_stack - start_time_stack\n",
    "\n",
    "print(f\"Stacking Classifier Runtime:  {stack_time:.2f} seconds\")\n",
    "print(\"\")\n",
    "print(f\"Weighted F1 Score, Stacking Classifier Train: {f1_score(y_train, y_pred_stack_train, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Stacking Classifier Train:  {log_loss(y_train, y_proba_stack_train)}\")\n",
    "print(f\"Weighted F1 Score, Stacking Classifier Test: {f1_score(y_test, y_pred_stack_test, average = 'weighted')}\")\n",
    "print(f\"Log Loss, Stacking Classifier Test:  {log_loss(y_test, y_proba_stack_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
